# Concepts
# Layers in Deep Learning Convolution Layer: Extracts spatial features like edges and patterns. Operates on local regions of the input using filters. Pooling Layer: Reduces spatial dimensions to decrease computation and prevent overfitting. Common types: Max Pooling, Average Pooling. Dense Layer (Fully Connected Layer): Connects all neurons to the next layer. Combines features for predictions in tasks like classification.
# Overfitting Definition: Model performs well on training data but poorly on unseen data. Solutions: Regularization: Apply Dropout, L1/L2 regularization. Data Augmentation: Increase diversity by flipping, rotating, scaling, etc. Reduce Complexity: Use fewer neurons or layers. Early Stopping: Stop training when validation loss stops improving.
# Vanishing Gradient Problem Definition: Gradients diminish during backpropagation, leading to poor updates in earlier layers. Solutions: Use ReLU activation instead of Sigmoid/Tanh. Batch Normalization to stabilize inputs. Residual Connections (ResNet) to skip layers and preserve gradients.
# Object Localization vs Object Detection Object Localization: Finds the position of one object in an image using bounding boxes. Object Detection: Identifies and localizes multiple objects in an image. Example Algorithm: R-CNN. R-CNN Workflow: Region Proposal: Identify possible object regions. Feature Extraction: Use CNN on proposals. Classification: Classify objects and refine bounding boxes.
# Activation Functions Tanh: Range: [-1, 1]. Used in hidden layers; zero-centered output simplifies optimization. ReLU (Rectified Linear Unit): Range: [0, âˆž]. Efficient, avoids vanishing gradients. Softmax: Converts logits into probabilities for multi-class classification. Output range: [0, 1], with the sum of all probabilities = 1.
# Transfer Learning Definition: Leverages pre-trained models (e.g., MobileNet, EfficientNet) for a new task. Steps: Load a pre-trained model (e.g., MobileNetV3). Freeze base layers to retain learned features. Add custom layers for the specific task (e.g., classification). Fine-tune by unfreezing top layers if needed.
# U-Net for Semantic Segmentation Definition: A popular architecture for pixel-wise image segmentation tasks. Key Components: Encoder: Extracts features using convolutional layers. Bottleneck: Connects encoder and decoder. Decoder: Upsamples features to reconstruct the segmented output. Loss Function: Binary Crossentropy + Jaccard Loss for binary masks. Metrics: Intersection over Union (IoU): Measures overlap between predicted and true masks.
# Dropout vs Batch Normalization Dropout: Regularization technique to prevent overfitting. Randomly deactivates neurons during training. Used in fully connected and convolutional layers. Batch Normalization: Normalizes inputs to each layer to stabilize training. Helps combat vanishing/exploding gradients. Applied after convolutional/dense layers, before activation functions.
# Data Generators ImageDataGenerator: Dynamically loads and preprocesses batches of images. Can apply real-time augmentations like rotation, flipping, zooming, etc. Custom Data Generator: Used for tasks like segmentation, pairing images with corresponding masks.
# Key Callbacks ModelCheckpoint: Saves the best model based on a monitored metric (e.g., validation loss). EarlyStopping: Stops training when the validation loss stops improving, avoiding overfitting. Key Metrics Loss: Measures how well the model is performing (e.g., Crossentropy, Jaccard Loss). Accuracy: Measures the percentage of correct predictions. IoU (Intersection over Union): Measures the overlap between the predicted and true regions in segmentation tasks.

# %%
import tensorflow as tf
from PIL import Image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, GlobalAveragePooling2D

gpu_devices = tf.config.list_physical_devices('GPU')

if not gpu_devices:
    print("TensorFlow is using the CPU.")
else:
    print(f"TensorFlow is using the following GPU(s): {gpu_devices}")

# %%
train_dir = '3_food_classes/train/'
test_dir = '3_food_classes/test/'

# %%
IMG_SIZE = (32,32)
image_datagen = ImageDataGenerator(rescale=1./255)

train_images = image_datagen.flow_from_directory(
    '3_food_classes/train/',
    target_size=IMG_SIZE,
    color_mode='grayscale',
    batch_size=20,
    class_mode='categorical'
)
test_images = image_datagen.flow_from_directory(
    '3_food_classes/test/',
    target_size=IMG_SIZE,
    color_mode='grayscale',
    batch_size=20,
    class_mode='categorical'
)

# %%
from keras.layers import Dense, Conv2D, MaxPooling2D

base_model = Sequential([
  Conv2D(32, (3,3), activation='relu', input_shape=(*IMG_SIZE, 1)),
  MaxPooling2D(2,2),
  Flatten(),
  Dense(32, activation='relu'),
  Dense(3, activation='softmax')
])

base_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
base_model.summary()

# %%
base_model.fit(train_images, epochs=10, validation_data=test_images)

# %%
IMG_SIZE=(128,128)

datagen = ImageDataGenerator(
  rescale=1./255,
  shear_range=0.2,
  zoom_range=0.2,
  horizontal_flip=True,
  rotation_range=90
)

# Go for color images
train_data = datagen.flow_from_directory(
    train_dir,
    target_size=IMG_SIZE,
    batch_size=32,
    class_mode='categorical'
)

test_data = image_datagen.flow_from_directory(
    test_dir,
    target_size=IMG_SIZE,
    batch_size=32,
    class_mode='categorical'
)

# %%
from keras.layers import Dropout, BatchNormalization

improved_model = Sequential([
  Conv2D(64, (3,3), activation='relu', input_shape=(*IMG_SIZE, 3)),
  MaxPooling2D(2,2),

  Conv2D(64, (3,3), activation='relu'),
  MaxPooling2D(2,2),

  Conv2D(128, (3,3), activation='relu'),
  MaxPooling2D(2,2),

  Flatten(),
  Dense(128, activation='relu'),
  Dropout(0.25),
  Dense(3, activation='softmax')
])

improved_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
improved_model.summary()

# %%
from keras.callbacks import EarlyStopping
es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=5, restore_best_weights=True)
history = improved_model.fit(train_data, epochs=5, validation_data=test_data, callbacks=[es])

# %%
print(f'Best score : {max(history.history['val_accuracy'])}')
es.best_weights

# %%
IMG_SIZE = (128,128)

train_data = ImageDataGenerator(
  rescale=1./255,
  shear_range=0.2,
  zoom_range=0.2,
  horizontal_flip=True
).flow_from_directory(
  train_dir,
  target_size=IMG_SIZE,
  batch_size=32,
  class_mode='categorical'
)

test_data = ImageDataGenerator(rescale=1./255).flow_from_directory(
  test_dir,
  target_size=IMG_SIZE,
  batch_size=32,
  class_mode='categorical'
)

# %%
from keras.applications import MobileNetV3Small
cust_model = MobileNetV3Small(input_shape=(*IMG_SIZE,3), weights=None)
# cust_model = ResNet50(input_shape=(*IMG_SIZE,3), weights='imagenet', include_top=False)
cust_model.trainable = False

new_model = Sequential([
    cust_model,
    Flatten(),
    Dense(64, activation='relu'),
    Dense(3, activation='softmax')
])

new_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

new_model.summary()

# %%
history = improved_model.fit(train_data, epochs=5, validation_data=test_data, callbacks=[es])

# %%
es.best

# %%
from keras.preprocessing.image import load_img, img_to_array

def load_images(folder, shape):
  images = []
  for filename in os.listdir(folder):
    img_path = os.path.join(folder, filename)
    img = load_img(img_path, target_size=shape)
    img = img_to_array(img)
    images.append(img)
  return np.array(images)

def show_image(image, mask):
  plt.imshow(image)
  plt.imshow(mask, alpha=0.5)
  plt.show()

# %%
base_dir = "../Unet_Dataset/"
images = load_images(base_dir+"images", (128,128))
masks = load_images(base_dir+"MASKS_BW", (128,128))

images = images/255.0
masks = masks/255.0

masks = np.expand_dims(masks[...,0], axis=-1)

show_image(images[0], masks[0])
masks.shape

# %%
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(images, masks, test_size=0.2, random_state=42)

# %%
os.environ['SM_FRAMEWORK'] = "tf.keras"
import segmentation_models as sm

# %%
model = sm.Unet('resnet34', encoder_weights='imagenet', input_shape=(*IMG_SIZE,3), classes=1, activation='sigmoid')
preprocess_input = sm.get_preprocessing('resnet34')

# %%
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[sm.metrics.iou_score])

# %%
X_train = preprocess_input(X_train)
X_test = preprocess_input(X_test)
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=5, verbose=True)

# %%
pred_set = model.predict(X_test)

# %%
show_image(X_test[0], pred_set[0].squeeze())


